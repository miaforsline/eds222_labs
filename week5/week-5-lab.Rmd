---
title: "EDS 222: Week 5: In-class Lab"
author: "Mia Forsline"
date: "`r Sys.Date()`"
output:
  tufte::tufte_html: default
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
---

# Section 0: Getting set up

You should already have done the following:

1.  Create a *Labs/* folder where you will store all your lab materials for EDS 222.
2.  Download `_common.R` and put it in the *Labs/* folder.
3.  Install the following packages:

```{r setup, include=FALSE, echo = FALSE, eval = FALSE}
suppressMessages({
  install.packages( "tidymodels", "gghighlight", "glue", "ggmosaic", "ggridges", "gridExtra", "infer", "janitor", "knitr", "kableExtra", "maps", "openintro", "patchwork", "quantreg", "tidyverse", "scales", "skimr", "caret", "palmerpenguins", "survival", "waffle", "ggrepel", "ggpubr", "openintro")
})
```

For today, load the following packages:

```{r, echo = FALSE, eval = TRUE}
# You probably already have these packages installed, so let's just load them
library(tidyverse)
library(readr)
library(ggplot2)
library(modelr)
library(knitr)
library(broom)

options(scipen = 999) # disable scientific notation

# For labs, we want to see all our code
knitr::opts_chunk$set(echo = TRUE)
```

# Section 1: Interactions in OLS in `R`

In this section we will focus on estimating an *interaction* model in `R`. Recall from lecture that an interaction model is appropriate when you think the effect of some variable $x$ on your dependent variable $y$ depends on a third variable $z$. For example, Graff-Zivin and Neidell (2012) find that the productivity of female agricultural workers is less sensitive to air pollution than that of men's. This suggests that *gender* influences the relationship between *productivity* and *pollution*.

To learn how to estimate interaction models, we will use an example from the automobile industry (from last week) which has data on fuel efficiency and automobile characteristics for cars of two vintages: 1999 cars, and 2008 cars. Last week we found that vintage influenced fuel efficiency: more recent cars have higher miles per gallon. We also found that our estimates were biased if we did not also control for engine size, as higher engine sizes lead to lower fuel efficiency, and they are also correlated with vintage.

## Parallel slopes model:

The model we estimated last week was:

$$hwy_i =\beta_{0}+\beta_{1} \cdot displ_i +\beta_{2} \cdot \text vintage_i+\varepsilon_i$$

The results of this "parallel slopes" model from last week looked like this:

```{r, echo=TRUE}
mpg <- mpg %>% mutate(year = as.factor(year)) # Recall, we do this to ensure our year variable is treated as a categorical variable

mod <- lm(hwy ~ displ + year, data = mpg)

mpg %>% 
  ggplot(aes(x = displ, y = hwy, color = year)) +
  geom_point() +
  geom_line(data = augment(mod), aes(y = .fitted, color = year)) + 
  labs(x = "Engine Displacement, in litres",
       y = "Highway Miles per gallon") +
  scale_colour_discrete("Year")
```

These slopes being **parallel** comes from our regression equation having just one coefficient on engine size; regardless of your vintage, we estimate the same impact of engine size on fuel economy.

This may not be accurate. If technology is improving over time, the effect of engine size on fuel economy could decline over time -- having a larger engine lowers fuel economy, but maybe we are getting better at not sacrificing miles per gallon as we increase engine size. In this subsection, we want to see if this true or or not. We will use the `mpg` dataset and is pre-loaded in `R`.

## Interaction model

We hypothesize that the relationship between miles per gallon and engine size may not actually be the same across the two vintages. That is, we want a model in which those "parallel slopes" above are allowed to differ by vintage.

We use an interaction model to achieve this: $$hwy_i=\beta_{0}+\beta_{1} \cdot displ_i + \beta_{2} \cdot vintage_i + \beta_{3} \cdot displ_i \cdot vintage_i + \varepsilon_i$$ The `lm` package makes estimating interactions easy. Just use a colon (`:`) between the two variables you want to interact; the colon tells `lm` to multiply the two variables by one another.

Complete the following:

1.  Using the model specified above, use `lm()` to estimate all three coefficients using the `mpg` data. Make sure you are treating `year` as a categorical variable! Use `summary(lm())` to print the regression results.

```{r}
mod_int <- lm(hwy ~ displ + year + displ:year, data = mpg)
summary(mod_int)
```

2.  What does the intercept tell you, in words?\
    \
    Intercept = $\beta_{0}$ = `mod_int$coefficients[1]`\
    \
    On average, when engine displacement is zero, fuel efficiency (for both 1999 cars) is `r mod_int$coefficients[1]` miles per gallon. \
    \
    Note: displacement of zero Liters isn't realistic

3.  What does the coefficient on `displ` tell you, in words?\
    \
    As displacement increases by one unit (one Liter), miles per gallon decreases by `mod_int$coefficients[2]` for 1999 cars. \
    \
    To interpret $\beta_{1}$, we must turn off the 2008 dummy variable to get rid of $\beta_{2}$ and $\beta_{3}$

4.  What does the coefficient estimate on the 2008 vintage indicator variable (`year2008`) tell you, in words?\
    \
    When the `year2008` dummy is turned on, it tells us the difference in mpg between the 1999 car with no engine and the 2008 car with no engine. \
    \
    If we stopped here, we would have a parallel slopes model. \
    \
    To isolate $\beta_{2}$, we have to turn off $\beta_{1}$ and assume displacement = 0.

5.  What does the coefficient on `displ:year2008` tell you, in words?[^1]\
    \
    The change in mpg due to 1 unit of engine displacement between 2008 and 1999 cars. (change of a change = difference in slopes) \
    \
    1999 cars mpg decreases by -3.7684 mpg per liter of displacement\
    2008 cars mpg decreases by (-3.7684 + 0.3052) mpg per liter of displacement \
    \
    Both `displ` and `year2008` are turned on. \
    \
    $\beta_{3}$ is the difference in the slopes for 1999 and 2008. For every 1L of displacement, there will be an additional 0.3052 difference between 2008 and 1999.

[^1]: Hint: This is tricky. Start by writing down the relationship between miles per gallon and engine size when the car vintage is 2008. Then write the same thing for car vintage 1999. Can you see what role this coefficient plays?

## Plotting an interaction model

Interaction models are difficult to interpret. Writing out the algebra of what each independent variable and its associated coefficient mean is really valuable, but visualizing the data and resulting model can also help. Here, let's remake our scatter plot above, but overlay our regression results from the interaction model.

**Intuition check before you dive in:** What do you expect to see in terms of intercepts and slopes of your vintage-specific regression lines?

As usual, `ggplot2` with `geom_smooth` plotting our regression line makes this easy for us. If we specify `color` as our grouping variable (i.e., car vintage year) in the first `ggplot()` command, and do not add aesthetics in `geom_point()`, or `geom_smooth()` later on, `geom_point` will *automatically* color scatter points by vintage year, and `geom_smooth()` will estimate whatever regression you specify *separately by vintage year*. This gives a coefficient and slope for each vintage, as our regression model above does.

Let's give it a try:

```{r}
#color aesthetic at the very top = R automatically allows different slopes of the lines
ggplot(data = mpg, aes(x = displ, y = hwy, color = year)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE)
  
```

Note that you could also plot the same thing using `augment()` as we did above, in combination with `geom_line()`. This gives you a bit more control over what is going on, since it's not obvious in the prior approach what regression exactly `geom_smooth()` is running.

First, run the interaction model. Then, use `geom_line()` to plot the regression lines using the fitted values from `augment()`.

```{r}
#summary(mod_int)
#augment(mod_int) 
#creating dataset with columns such as fitted data (predicted data) + residuals 

mpg %>% ggplot(aes(y = hwy, x = displ, color = year))+ 
  geom_point()+
  geom_line(data = augment(mod_int), aes(y = .fitted)) #plot the fitted/predicted values based on the model 
  
```

## Adjusted R-squared

We saw in the previous exercise that an interaction model resulted in different slopes for each group. However, is this more complex model actually "better"? We have explored using $R^2$ as a measure of model fit. It is a common one and you should be comfortable computing and interpreting it. Maybe it can help us answer the question of which model to use in this case.

However, as we discussed in lecture, $R^2$ *mechanically* increases as you add more independent variables to your regression. Adjusted $R^2$ is designed to "penalize" your measure of model fit for those additional independent variables.

These two measures are: $$R^{2}=1 - \frac{\sum_i e_i^2}{\sum_i (y_i - \bar y)^2}$$ $$ \overline{R}^2 = 1 - \dfrac{\sum_i e_i^2/(n-k-1)}{\sum_i \left( y_i - \overline{y} \right)^2/(n-1)} $$ **Did the added interaction term in our regression improve model fit?**

In this case, the interaction model added a new variable to our regression, so we should be comparing adjusted $R^2$ results from a model without the interaction to a model with it. You can see the adjusted $R^2$ in `summary(lm())`, but you can also access it by saving your `lm` object and calling `summary(mod)$adj.r.squared`.

```{r}

```
